# ðŸ§  Clasificador de COVID-19 por RadiografÃ­as (CASO INNOVACIÃ“N 2025)

Este proyecto permite clasificar imÃ¡genes de rayos X en tres categorÃ­as:
- **COVID-19**
- **NeumonÃ­a Viral**
- **Pulmones Normales**

DiseÃ±ado para funcionar en entornos con recursos limitados (mÃ¡ximo 12GB RAM, sin GPU), utilizando modelos optimizados con TensorFlow Lite.

---

## ðŸ“‚ Estructura del Proyecto

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # ImÃ¡genes originales
â”‚   â””â”€â”€ processed/        # ImÃ¡genes redimensionadas (150x150)
â”œâ”€â”€ model/                # Modelos entrenados (.h5 y .tflite)
â”œâ”€â”€ resize_images.py      # Preprocesamiento
â”œâ”€â”€ train_model.py        # Entrenamiento + conversiÃ³n TFLite
â”œâ”€â”€ classify_tflite.py    # ClasificaciÃ³n usando modelo .tflite
â”œâ”€â”€ dashboard_streamlit.py # Dashboard web interactivo
â”œâ”€â”€ requirements.txt      # Dependencias
â”œâ”€â”€ README.md
```

---

## âš™ï¸ Requisitos

- Python 3.10
- RAM â‰¤ 12GB (sin GPU)
- Tiempo de procesamiento â‰¤ 18h

---

## ðŸš€ InstalaciÃ³n

1. Clona el repositorio y crea un entorno virtual:

```bash
python -m venv venv
source venv/bin/activate  # o venv\Scripts\activate en Windows
```

2. Instala las dependencias:

```bash
pip install -r requirements.txt
```

---

## ðŸ› ï¸ Uso

### 1. Redimensionar imÃ¡genes:

```bash
python resize_images.py
```

Esto procesa las imÃ¡genes de `data/raw/` y guarda las nuevas versiones en `data/processed/`.

---

### 2. Entrenar y exportar el modelo:

```bash
python train_model.py
```

Esto entrenarÃ¡ una MobileNetV2 y generarÃ¡:

- `model/mobilenet_model.h5`
- `model/mobilenet_model.tflite` (cuantizado para CPU)

---

### 3. Clasificar una imagen (modo consola):

```bash
python classify_tflite.py
```

Este script carga el modelo `.tflite` y realiza inferencia sobre una imagen de prueba.

---

### 4. Dashboard Web (opcional):

```bash
streamlit run dashboard_streamlit.py
```

Te permite subir una imagen y obtener la predicciÃ³n en una interfaz simple.

---

## ðŸ“Š Resultados esperados

- **PrecisiÃ³n:** > 85%
- **RAM usada:** < 4GB en entrenamiento, < 1GB en inferencia
- **Tiempo de procesamiento total:** 6â€“10 horas para 3.6k imÃ¡genes (CPU)

---

## ðŸ“ˆ Innovaciones aplicadas

- MobileNetV2 con `transfer learning`
- CuantizaciÃ³n post-entrenamiento (`int8`)
- Uso de `tf.lite.Interpreter` para CPU
- Sin dependencias de GPU ni frameworks pesados